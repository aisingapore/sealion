name_or_path: aisingapore/sea-lion-7b
output_dir: models/example_sft_model
run_name: example_fine_tuning

num_train_epochs: 3
num_gpus: 8
seed:

prompt_format: sealion
system_prompt: null

lr_scheduler_type: cosine
learning_rate: 3e-5
num_warmup_steps: 100
weight_decay: 0.05
optimizer_type: adamw_torch
per_device_train_batch_size: 1
per_device_eval_batch_size: 1
gradient_accumulation_steps: 2
gradient_checkpointing: False
neftune_noise_alpha: 5

# dataset
datasets:
  dolly_hhrlhf:
    name: Abzu/dolly_hhrlhf
    type: hf
    language: en
    duplicate: 1
split: "train"
size_valid_set: 100
streaming: False
shuffle_buffer: 5000

seq_length: 2048
attn_impl: flash

peft:
  lora_alpha: 16
  lora_r: 16
  lora_dropout: 0.05
  target_modules: ["down_proj", "out_proj", "up_proj", "Wqkv"]

# model logging
log_with: mlflow
log_freq: 1
logging_steps: 10
save_steps: 5000
